{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.1 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "e774977668b7c0ae8309835a5187aa7fbf7669e7d0bb59755bc63e573643edcd"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# New Project"
      ],
      "metadata": {
        "id": "t3ZAarhZX6bg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "iNJxTTxoX7oQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# TPU\n",
        "# !pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8-cp37-cp37m-linux_x86_64.whl > /dev/null 2>&1\n",
        "\n",
        "!pip install pytorch-lightning --upgrade       > /dev/null 2>&1\n",
        "!pip install torchmetrics                      > /dev/null 2>&1\n",
        "!pip install lightning-bolts                   > /dev/null 2>&1\n",
        "!pip install thop                              > /dev/null 2>&1\n",
        "!pip install optuna                            > /dev/null 2>&1\n",
        "\n",
        "# Uncomment after https://github.com/neptune-ai/neptune-pytorch-lightning/issues/3 is resolved\n",
        "# !pip install neptune-client[pytorch-lightning] > /dev/null 2>&1\n",
        "!python -m pip install git+https://github.com/rshwndsz/neptune-pytorch-lightning.git@rsd/NPT-PL-3-use-existing-run > /dev/null 2>&1\n",
        "\n",
        "# Uncomment after https://github.com/neptune-ai/neptune-optuna/issues/6 is resolved\n",
        "# !pip install neptune-client[optuna]            > /dev/null 2>&1\n",
        "!python -m pip install git+https://github.com/rshwndsz/neptune-optuna.git@rsd/NPT-OPT-2-multi-objective-support > /dev/null 2>&1"
      ],
      "outputs": [],
      "metadata": {
        "id": "a4FYNFxPXF2v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# STL\n",
        "import math\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import logging\n",
        "import getpass\n",
        "import shutil\n",
        "import random\n",
        "import joblib\n",
        "import json\n",
        "from pathlib import Path\n",
        "from functools import partial\n",
        "from collections import OrderedDict\n",
        "from argparse import Namespace\n",
        "\n",
        "# Numerical Python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Image processing\n",
        "from PIL import Image\n",
        "\n",
        "# Deep Learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as D\n",
        "import torchvision as tv\n",
        "import torchvision.transforms as tf\n",
        "import torchvision.transforms.functional as tff\n",
        "import torchmetrics as M\n",
        "import pytorch_lightning as pl\n",
        "import neptune.new as neptune\n",
        "import optuna\n",
        "import thop\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Bells & Whistles\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from neptune.new.types import File\n",
        "from neptune.new.integrations.pytorch_lightning import NeptuneLogger\n",
        "from neptune.new.integrations.optuna import NeptuneCallback\n",
        "from optuna.integration import PyTorchLightningPruningCallback\n",
        "\n",
        "# Misc\n",
        "import gdown\n",
        "from tqdm.notebook import tqdm"
      ],
      "outputs": [],
      "metadata": {
        "id": "fs5eE9JbXNP6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import getpass\n",
        "\n",
        "C = Namespace(\n",
        "    NEPTUNE = Namespace(\n",
        "        USERNAME  = \"rshwndsz\",\n",
        "        PROJECT   = \"\", # TODO  \n",
        "        API_TOKEN = getpass.getpass(prompt=\"Neptune API Token: \"),\n",
        "    ),\n",
        "    SEED = 1337\n",
        ")\n",
        "\n",
        "pl.seed_everything(C.SEED)\n",
        "os.environ[\"NEPTUNE_API_TOKEN\"] = C.NEPTUNE.API_TOKEN"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "i-xIcmFTYSmn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class DataModule(pl.LightningDataModule):\n",
        "    def __init__(self, \n",
        "                batch_size  = 4, \n",
        "                num_workers = 2, \n",
        "                pin_memory  = True, \n",
        "                shuffle     = True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.batch_size  = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.pin_memory  = pin_memory\n",
        "        self.shuffle     = shuffle\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \"\"\"\n",
        "        For operations that might write to disk or \n",
        "        that need to be done only from a single process in distributed settings.\n",
        "        DO NOT use to assign state as it is called from a single process.\n",
        "        \"\"\"\n",
        "        URL    = \"\"\n",
        "        outdir = Path(\"./data/\")\n",
        "\n",
        "        # Safely create nested directory\n",
        "        outdir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Download dataset\n",
        "        if not (outdir / \"dataset.mat\").exists():\n",
        "            gdown.download(URL, str(outdir / \"dataset.mat\"), quiet=False)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        \"\"\"For data operations on every GPU.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        pass\n",
        "        \n",
        "    def val_dataloader(self):\n",
        "        pass\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        pass\n",
        "\n",
        "    def teardown(self, stage=None):\n",
        "        \"\"\"Used to clean-up when run is finished\"\"\"\n",
        "        pass\n",
        "    \n",
        "    def visualize(self):\n",
        "        pass"
      ],
      "outputs": [],
      "metadata": {
        "id": "nuxgRWpWYSGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Blocks"
      ],
      "metadata": {
        "id": "VBxTMxZ9cs3K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "63_8iSRzcs3L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "xwmGy6RSaYzx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class Net(pl.LightningModule):\n",
        "    def __init__(self, hparams):\n",
        "        super().__init__()\n",
        "\n",
        "        # Hyperparameters\n",
        "        self.save_hyperparameters(hparams)\n",
        "\n",
        "        # Metrics\n",
        "        _metrics  = M.MetricCollection({\n",
        "            \"AverageAccuracy\": M.Accuracy(num_classes=self.hparams.num_classes, average=\"macro\"),\n",
        "        })\n",
        "        self.train_metrics = _metrics.clone(prefix=\"train/\")\n",
        "        self.val_metrics   = _metrics.clone(prefix=\"val/\")\n",
        "        self.test_metrics  = _metrics.clone(prefix=\"test/\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        pass\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        pass\n",
        "\n",
        "    def loss_function(self, preds, targets):\n",
        "        pass\n",
        "\n",
        "    def prepare_data(self):\n",
        "        pass\n",
        "                  \n",
        "    def train_dataloader(self):\n",
        "        pass\n",
        "        \n",
        "    def val_dataloader(self):\n",
        "        pass\n",
        "        \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input, target = batch\n",
        "        pred          = self(input)\n",
        "        loss          = self.loss_function(pred, target)\n",
        "\n",
        "        self.log(\"train/loss\", loss)\n",
        "        return { 'loss': loss , \"pred\": pred, \"target\": target }\n",
        "\n",
        "    def training_step_end(self, outputs):\n",
        "        preds   = outputs['pred']\n",
        "        targets = outputs['target'] \n",
        "\n",
        "        m = self.train_metrics(preds, targets)\n",
        "        self.log_dict(m)\n",
        "        return outputs\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        input, target = batch\n",
        "        pred          = self(input)\n",
        "        loss          = self.loss_function(pred, target)\n",
        "\n",
        "        self.log(\"val/loss\", loss)\n",
        "        return { \"loss\": loss, \"pred\": pred, \"target\": target }\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        preds   = torch.cat([x['pred'] for x in outputs], dim=0)\n",
        "        targets = torch.cat([x['target'] for x in outputs], dim=0)\n",
        "\n",
        "        m = self.val_metrics(preds, targets)\n",
        "        self.log_dict(m)\n",
        "        return outputs\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        input, target = batch\n",
        "        pred          = self(input)\n",
        "        loss          = self.loss_function(pred, target)\n",
        "\n",
        "        self.log(\"test/loss\", loss)\n",
        "        return { \"loss\": loss, \"pred\": pred, \"target\": target }\n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        preds   = torch.cat([x['pred'] for x in outputs], dim=0)\n",
        "        targets = torch.cat([x['target'] for x in outputs], dim=0)\n",
        "\n",
        "        m = self.test_metrics(preds, targets)\n",
        "        self.log_dict(m)\n",
        "        return outputs"
      ],
      "outputs": [],
      "metadata": {
        "id": "57jkQ5F5aVs_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sweep"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class Objective:\n",
        "    def __init__(self, run, monitor):\n",
        "        self.run     = run        # Neptune Instance\n",
        "        self.monitor = monitor    # Metric to be monitored \n",
        "\n",
        "    def __call__(self, trial):\n",
        "        which_trial = trial.number \n",
        "        use_gpu     = torch.cuda.is_available() \n",
        "\n",
        "        tunable = Namespace(\n",
        "\n",
        "        )\n",
        "\n",
        "        nlogger = NeptuneLogger(\n",
        "            run             = self.run,\n",
        "            base_namespace  = f\"sweep/trial_{which_trial}\",\n",
        "            close_after_fit = False\n",
        "        )\n",
        "\n",
        "        # dataset = \n",
        "        # run[\"dataset\"].log(dataset.__class__.__name__)\n",
        "\n",
        "        # model = \n",
        "        # run[\"model\"].log(model.__class__.__name__)\n",
        "\n",
        "        trainer = pl.Trainer(\n",
        "            gpus                      = -1 if use_gpu else 0,\n",
        "            precision                 = tunable.precision if use_gpu else 32,\n",
        "            deterministic             = True,\n",
        "            benchmark                 = True,\n",
        "\n",
        "            max_epochs                = 33,\n",
        "            num_sanity_val_steps      = 2,\n",
        "            check_val_every_n_epoch   = 2,\n",
        "\n",
        "            weights_summary           = \"full\",\n",
        "            progress_bar_refresh_rate = 20,\n",
        "            gradient_clip_val         = tunable.gradient_clip_val,\n",
        "            stochastic_weight_avg     = tunable.stochastic_weight_avg,\n",
        "            logger                    = nlogger,\n",
        "            checkpoint_callback       = False,\n",
        "            # callbacks                 = [PyTorchLightningPruningCallback(trial, monitor=self.monitor)],\n",
        "        )\n",
        "\n",
        "        trainer.fit(model, dataset)\n",
        "\n",
        "        accuracy = trainer.callback_metrics[self.monitor].item()\n",
        "\n",
        "        # _inputs  = \n",
        "        flops, num_parameters = thop.profile(model, inputs=_inputs, verbose=False)\n",
        "\n",
        "        return accuracy, num_parameters\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "run = neptune.init(\n",
        "    project   = f\"{C.NEPTUNE.USERNAME}/{C.NEPTUNE.PROJECT}\",\n",
        "    name      = \"sweep\",\n",
        "    api_token = C.NEPTUNE.API_TOKEN,\n",
        "    mode      = \"debug\",\n",
        ")\n",
        "\n",
        "study = optuna.study.create_study(\n",
        "    directions     = [\"maximize\", \"minimize\"],\n",
        "    # pruner         = optuna.pruners.MedianPruner(),\n",
        ")\n",
        "\n",
        "# Resume from here\n",
        "study.optimize(\n",
        "    Objective(run, \"val/AverageAccuracy\"), \n",
        "    n_trials  = 100,\n",
        "    callbacks = [NeptuneCallback(run)]\n",
        ")\n",
        "run.stop()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "Bdb6OMKha1N3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "run = neptune.init(\n",
        "    project   = f\"{C.NEPTUNE.USERNAME}/{C.NEPTUNE.PROJECT}\",\n",
        "    name      = \"sweep\",\n",
        "    api_token = C.NEPTUNE.API_TOKEN,\n",
        "    mode      = \"debug\",\n",
        ")\n",
        "\n",
        "# Logger\n",
        "nlogger = NeptuneLogger(\n",
        "    run             = run,\n",
        "    base_namespace  = \"training\",\n",
        "    close_after_fit = False # Keep open for testing\n",
        ")\n",
        "\n",
        "# Get parameters from best study\n",
        "best = Namespace(**run[\"best/params\"].fetch())\n",
        "\n",
        "# Save best model every 5 val_epochs\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    monitor    = \"val/AverageAccuracy\",\n",
        "    mode       = \"max\",\n",
        "    verbose    = True\n",
        "    period     = 5,\n",
        "    save_top_k = 5,\n",
        "    save_last  = True,\n",
        "    dirpath    = \"./checkpoints/\",\n",
        "    filename   = \"epoch-{epoch:03d}__val_AverageAccuracy-{val/AverageAccuracy:.4f}\",\n",
        "    auto_insert_metric_name = False,\n",
        ")\n",
        "\n",
        "# Stop training if model stops improving\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor      = \"val/AverageAccuracy\", \n",
        "    mode         = \"maxx\", \n",
        "    patience     = 10, \n",
        "    min_delta    = 1e-6, \n",
        "    strict       = True, \n",
        "    check_finite = True,\n",
        "    verbose      = True, \n",
        ")\n",
        "\n",
        "# Dataset\n",
        "# TODO\n",
        "\n",
        "# Model\n",
        "# TODO\n",
        "\n",
        "# Trainer\n",
        "trainer = pl.Trainer(\n",
        "    gpus                      = -1 if torch.cuda.is_available() else 0,\n",
        "    precision                 = best.precision if torch.cuda.is_available() else 32,\n",
        "    deterministic             = True,\n",
        "    benchmark                 = True,\n",
        "\n",
        "    min_epochs                = 50\n",
        "    max_epochs                = 1000,\n",
        "    num_sanity_val_steps      = 4,\n",
        "    check_val_every_n_epoch   = 4,\n",
        "\n",
        "    gradient_clip_val         = best.gradient_clip_val,\n",
        "    stochastic_weight_avg     = best.stochastic_weight_avg,\n",
        "    weights_summary           = \"full\",\n",
        "    progress_bar_refresh_rate = 20,\n",
        "\n",
        "    logger                    = nlogger,\n",
        "    callbacks                 = [model_checkpoint, early_stopping],\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "-53FRnJxa3b8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 🐉\n",
        "trainer.fit(model, dataset)"
      ],
      "outputs": [],
      "metadata": {
        "id": "2Qnj1zATbRcz"
      }
    }
  ]
}